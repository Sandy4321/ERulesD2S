package net.sf.jclec.problem.classification.evolutionarylearner;

import java.util.Comparator;
import java.util.Random;

import com.yahoo.labs.samoa.instances.Instances;

import net.sf.jclec.IFitness;
import net.sf.jclec.IIndividual;
import net.sf.jclec.base.AbstractParallelEvaluator;
import net.sf.jclec.fitness.SimpleValueFitness;
import net.sf.jclec.fitness.ValueFitnessComparator;
import net.sf.jclec.problem.classification.base.Rule;
import net.sf.jclec.problem.classification.syntaxtree.SyntaxTreeRuleIndividual;

public class RuleEvaluator extends AbstractParallelEvaluator
{
	/////////////////////////////////////////////////////////////////
	//--------------------------------------- Serialization constant
	/////////////////////////////////////////////////////////////////

	/** Generated by Eclipse */

	private static final long serialVersionUID = 3613350191235561000L;

	// ///////////////////////////////////////////////////////////////
	// --------------------------------------------------- Properties
	// ///////////////////////////////////////////////////////////////

	protected ValueFitnessComparator comparator = new ValueFitnessComparator(false);

	protected Instances[] datasets;
	
	protected int numberWindows;

	protected int currentWindow;
	
	protected double fadingFactor;
	
	protected Random randomGenerator = new Random();

	// ///////////////////////////////////////////////////////////////
	// ------------------------------------------------- Constructors
	// ///////////////////////////////////////////////////////////////

	public RuleEvaluator() {
		super();
	}

	public Comparator<IFitness> getComparator() {		
		return comparator;
	}
	
	public void setNumberWindows(int numberWindows) {
		this.numberWindows = numberWindows;
		datasets = new Instances[numberWindows];
	}
	
	public void setFadingFactor(double fadingFactor) {
		this.fadingFactor = fadingFactor;
	}

	// ///////////////////////////////////////////////////////////////
	// ------------------------ Overwriting AbstractEvaluator methods
	// ///////////////////////////////////////////////////////////////

	/**
	 * Evaluates the individual and compute it fitness 
	 * 
	 * @param individual Individual to evaluate
	 */

	public void evaluate(IIndividual individual) 
	{
		Rule rule = (Rule) ((SyntaxTreeRuleIndividual) individual).getPhenotype();

		int tp = 0, fp = 0, tn = 0, fn = 0;

		// Calculate the confusion matrix
		for(Instances dataset : datasets)
			if(dataset != null)
			{
				for(int i = 0; i < dataset.numInstances(); i++)
				{
					if((Boolean) rule.covers(dataset.instance(i)))
					{		
						if (dataset.instance(i).classValue() == rule.getConsequent())
							tp++;
						else
							fp++;
					}
					else
					{
						if (dataset.instance(i).classValue() != rule.getConsequent())
							tn++;
						else
							fn++;
					}
				}
			}

		double se, sp;

		if(tp + fn == 0)
			se = 1;
		else
			se = (double) tp / (tp + fn);

		if(tn + fp == 0)
			sp = 1;
		else
			sp = (double) tn / (tn + fp);

		// Set the fitness to the individual
		double fitness = se * sp;

		individual.setFitness(new SimpleValueFitness(fitness));
	}

	public void addChunkData(Instances chunkInstances)
	{
		datasets[currentWindow] = chunkInstances;
		
		for(int w = 1; w < numberWindows; w++)
		{
			Instances dataset = datasets[(currentWindow + w) % numberWindows];
			
			if(dataset != null)
			{
				int numInstancesToRemove = (int) (dataset.numInstances() * fadingFactor);
				
				for(int i = 0; i < numInstancesToRemove; i++)
					dataset.delete(randomGenerator.nextInt(dataset.size()));
			}
		}
		
		currentWindow = (currentWindow + 1) % numberWindows;
	}
}